# Issue: SOOP Acute Stroke Dataset (ds004889)

**Status:** Ready for upstream
**Difficulty:** ⭐⭐ Medium (large dataset, standard structure)
**Labels:** `enhancement`, `dataset`, `help wanted`

---

## Title

`[Dataset] Add SOOP (ds004889) - Acute Stroke Imaging (1714 subjects)`

---

## Body

### Dataset Info

| Field | Value |
|-------|-------|
| **Name** | Stroke Outcome Optimization Project (SOOP) |
| **Source** | [OpenNeuro ds004889](https://openneuro.org/datasets/ds004889) |
| **Paper** | [PubMed 39095364](https://pubmed.ncbi.nlm.nih.gov/39095364/) |
| **License** | CC0 (Public Domain) |
| **Subjects** | 1714 (1449 confirmed stroke) |
| **Format** | BIDS |
| **Size** | ⚠️ **>600 GB** (large download) |
| **HuggingFace Target** | `hugging-science/soop-acute-stroke` |

### Description

SOOP is the **acute** stroke companion to [ARC (chronic stroke)](https://huggingface.co/datasets/hugging-science/arc-aphasia-bids). Together they enable acute→chronic outcome prediction research.

**Data includes:**
- T1-weighted structural MRI
- FLAIR
- Diffusion-weighted imaging (DWI) with ADC/TRACE maps
- Demographics (Safe Harbor compliant)
- Behavioral measures

### Why This Matters

1. **Completes the stroke timeline** - ARC has chronic, SOOP has acute
2. **Clinical ML applications** - Acute stroke outcome prediction
3. **Large scale** - 1714 subjects for robust training
4. **Proves pipeline** - Tests bids-hub against a new dataset structure

### Exact Schema

```python
from datasets import Features, Value
from datasets.features import Nifti, Sequence

def get_soop_features() -> Features:
    """SOOP schema - one row per SUBJECT (most are single-session).

    Note: Most acute stroke patients have a single session. If multi-session
    exists, consider one row per SESSION like ARC.
    """
    return Features({
        "subject_id": Value("string"),      # e.g., "sub-M2001"
        # Structural
        "t1w": Nifti(),                     # *_T1w.nii.gz
        "flair": Nifti(),                   # *_FLAIR.nii.gz
        # Diffusion (critical for acute stroke)
        "dwi": Sequence(Nifti()),           # *_dwi.nii.gz (may have multiple)
        "adc": Nifti(),                     # *_adc.nii.gz (Apparent Diffusion Coefficient)
        "trace": Nifti(),                   # *_trace.nii.gz (if available)
        # Metadata from participants.tsv
        "age": Value("float32"),
        "sex": Value("string"),
        "nihss": Value("float32"),          # NIH Stroke Scale (verify column name)
    })
```

> **Implementation Note:** Verify `participants.tsv` column names during implementation.
> NIHSS may be named differently (e.g., `nihss_admission`, `NIHSS`, etc.).

### Directory Structure

```text
ds004889/
├── participants.tsv
├── participants.json
├── dataset_description.json
└── sub-XXXXX/
    └── ses-XX/
        ├── anat/
        │   ├── sub-XXXXX_ses-XX_T1w.nii.gz
        │   └── sub-XXXXX_ses-XX_FLAIR.nii.gz
        └── dwi/
            ├── sub-XXXXX_ses-XX_dwi.nii.gz
            ├── sub-XXXXX_ses-XX_dwi.bval
            └── sub-XXXXX_ses-XX_dwi.bvec
```

### Files to Create

```text
src/bids_hub/datasets/soop.py          # Dataset module (follow arc.py pattern)
src/bids_hub/validation/soop.py        # Validation rules
scripts/download_soop.sh               # Download script (S3: s3://openneuro.org/ds004889)
tests/test_soop.py                     # Tests (follow test_arc.py pattern)
docs/dataset-cards/soop-acute-stroke.md  # Dataset card (follow arc-aphasia-bids.md pattern)
```

### Implementation Steps

1. **Create download script** (`scripts/download_soop.sh`)
   ```bash
   # WARNING: This dataset is >600 GB. Ensure sufficient disk space.
   aws s3 sync --no-sign-request s3://openneuro.org/ds004889 "$TARGET_DIR"
   ```

2. **Create dataset module** (`src/bids_hub/datasets/soop.py`)
   - Copy `arc.py` as template
   - Implement `build_soop_file_table()` - walk sub-*/ses-*/anat/ and dwi/
   - Implement `get_soop_features()` - schema above
   - Implement `build_and_push_soop()`

3. **Add CLI commands** (in `cli.py`)
   ```python
   @app.command()
   def soop():
       """SOOP dataset commands."""
   # Subcommands: validate, build, info
   ```

4. **Add validation** (`src/bids_hub/validation/soop.py`)
   - Check participants.tsv exists
   - Check at least T1w OR FLAIR per subject
   - Warn if DWI missing (important for acute stroke)

5. **Add tests** (`tests/test_soop.py`)
   - Follow `test_arc.py` pattern
   - Create synthetic BIDS fixture with SOOP structure

6. **Upload to HuggingFace**
   ```bash
   uv run bids-hub soop build /path/to/ds004889 --hf-repo hugging-science/soop-acute-stroke --no-dry-run
   ```
   - Use `num_shards=1714` (one per subject) to prevent OOM

### Acceptance Criteria

- [ ] `scripts/download_soop.sh` downloads dataset successfully
- [ ] `uv run bids-hub soop validate <path>` passes
- [ ] `uv run bids-hub soop build <path> --dry-run` succeeds
- [ ] `uv run pytest tests/test_soop.py` passes
- [ ] `uv run ruff check . && uv run mypy src tests` clean
- [ ] Dataset uploaded to `hugging-science/soop-acute-stroke`
- [ ] HuggingFace README.md with proper frontmatter, usage examples, and citation
- [ ] `docs/dataset-cards/soop-acute-stroke.md` added (follow `arc-aphasia-bids.md` pattern)

### Resources

- [OpenNeuro ds004889](https://openneuro.org/datasets/ds004889)
- [SOOP Processing Demo (Chris Rorden)](https://github.com/neurolabusc/StrokeOutcomeOptimizationProjectDemo)
- [Existing ARC implementation](src/bids_hub/datasets/arc.py) - use as template
- [arc-aphasia-bids on HF](https://huggingface.co/datasets/hugging-science/arc-aphasia-bids) - reference

### Citation

```bibtex
@dataset{soop2024,
  title={Stroke Outcome Optimization Project (SOOP)},
  author={Rorden, Chris and colleagues},
  year={2024},
  publisher={OpenNeuro},
  doi={10.18112/openneuro.ds004889.v1.0.0}
}
```
